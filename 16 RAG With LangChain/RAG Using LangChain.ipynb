{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013e6b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain) (0.3.59)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain) (0.3.42)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from faiss-cpu) (2.2.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from requests) (2025.4.26)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain faiss-cpu  tiktoken requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffdb3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting euriai\n",
      "  Using cached euriai-0.3.3-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from euriai) (2.32.3)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from euriai) (0.3.59)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core->euriai) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core->euriai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core->euriai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core->euriai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core->euriai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core->euriai) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langchain-core->euriai) (2.11.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from requests->euriai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from requests->euriai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from requests->euriai) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from requests->euriai) (2025.4.26)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->euriai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core->euriai) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core->euriai) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core->euriai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core->euriai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core->euriai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core->euriai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core->euriai) (0.4.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core->euriai) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core->euriai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core->euriai) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\scl\\anaconda3\\envs\\agentdemo\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core->euriai) (1.3.1)\n",
      "Using cached euriai-0.3.3-py3-none-any.whl (5.7 kB)\n",
      "Installing collected packages: euriai\n",
      "Successfully installed euriai-0.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install euriai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1640fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.llms.base import LLM\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "import numpy as np\n",
    "import faiss\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f0722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(text: str) :\n",
    "    url = \"https://api.euron.one/api/v1/euri/alpha/embeddings\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {EURI_API_KEY}\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"input\":text,\n",
    "        \"model\": \"text-embedding-3-small\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Convert to numpy array for vector operations\n",
    "    embedding = np.array(data['data'][0]['embedding'])\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db60f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from euriai import EuriaiClient\n",
    "def generate_response(prompt):\n",
    "    client = EuriaiClient(\n",
    "        api_key= EURI_API_KEY,\n",
    "        model=\"gpt-4.1-nano\"  \n",
    "    )\n",
    "\n",
    "    response = client.generate_completion(\n",
    "        prompt=prompt,\n",
    "        temperature=0,\n",
    "        max_tokens=300\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "    return response['choices'][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4bf734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"\\nMaking an Impact\\nHelping Millions of Students Succeed\\nSudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.\\n\\nIn 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.\\n\\nThe Entrepreneur and Teacher: Sudhanshu's Dual Legacy\\nSudhanshu's journey isn't just one of entrepreneurial success; it's also a story of dedication to teaching. Throughout his career, he has remained a passionate educator, constantly looking for ways to empower others through knowledge. Whether teaching courses in Big Data, Data Science, or programming, Sudhanshu has always sought to make complex subjects accessible to learners at all levels.\\n\\nHis commitment to affordable education has earned him the respect and admiration of countless students. Many credit Sudhanshu with changing their lives, helping them secure jobs, improve their skills, and break free from the limitations of their backgrounds.\\n\\nThe Journey\\n\\nEarly Life and the Power of Education\\n\\nRising Through the Ranks of the Tech World\\n\\nThe Birth of iNeuron: Democratizing Education\\n\\nThe Foundation of Euron: Expanding the Mission\\nEarly Life and the Power of Education\\nEarly Life and the Power of Education\\nSudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.\\n\\nWhile many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).\\n\\nAfter completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.\\n\\nDespite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.\\nFueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.\\n\\niNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no student would be left behind due to financial constraints.\\n\\nThe company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience.\\n\\nBuilding on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\\n\\nFor individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\\n\\nThe Euron Motto: Education for All, Without Limits\\n\\nAt the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\\n\\nHome >\\n\\nGenerative AI\\nGenerative AI with Cloud\\nGenerative AI with Cloud is a practical course that combines generative AI techniques with cloud platforms like AWS, Azure, and GCP. Learn to deploy and scale models, integrate APIs, manage storage, and build intelligent applications using tools like Vertex AI, Bedrock, and OpenAI. Ideal for real-world, cloud-powered AI solutions.\\n\\n🌐\\nEnglish\\nGenerative AI with Cloud\\nThis course is included in plans\\n\\n📚\\nContinue Learning\\nWhat you will get\\ntick-svg\\nCertificate of Completion\\n\\ntick-svg\\nWhatsApp Group Access\\n\\ntick-svg\\nEURI AI Tool Access\\n\\ntick-svg\\nResume AI Tool\\n\\ntick-svg\\nJob Portal Access\\n\\ntick-svg\\nAvni – AI Interview Coach\\n\\ntick-svg\\nNo Prerequisites Required\\n\\ntick-svg\\nQuiz in Every Module\\n\\ntick-svg\\nChallenges in Every Module\\n\\ntick-svg\\nCareer-Ready Portfolio\\n\\ntick-svg\\nResources in all Module\\n\\ntick-svg\\nOne module release every Monday\\n\\nCourse content\\n12 sections • 100 Subtopics\\n\\nCollapse all sections\\n\\nIntroduction to Generative AI in the Cloud\\nTopic Icon\\nWhat is Generative AI in a Cloud Context?\\nTopic Icon\\nDifferences Between Local vs Cloud-Based Generative AI\\nTopic Icon\\nUse Cases: AI Agents, Chatbots, Text-to-Image, Code Assistants\\nTopic Icon\\nCloud Provider Comparison: AWS vs Azure vs GCP vs Hugging Face vs OpenAI\\nTopic Icon\\nKey Components: Model APIs, Storage, Serverless Compute, GPU Instances, Vector DBs\\n\\nGenAI Building Blocks & Architecture\\nTopic Icon\\nCore Architecture: Frontend ↔ API Layer ↔ Model ↔ Storage\\nTopic Icon\\nDeployment Flow: Prompt → Model API → Output → Logging\\nTopic Icon\\nCloud GenAI Architecture Patterns\\nTopic Icon\\nRAG Pipeline\\nTopic Icon\\nAgent Execution Flow\\nTopic Icon\\nImage + Text Generation\\nTopic Icon\\nDev Tools: GitHub, VS Code, LangChain, Streamlit/Gradio, FastAPI\\n\\nGenAI on AWS\\nTopic Icon\\nAWS Bedrock\\nTopic Icon\\nAccessing Claude, Titan, LLaMA via Bedrock\\nTopic Icon\\nBedrock API setup and playground\\nTopic Icon\\nAmazon SageMaker JumpStart\\nTopic Icon\\nDeploying Pre-trained Foundation Models (T5, Falcon)\\nTopic Icon\\nFine-Tuning & Inference Endpoint\\nTopic Icon\\nHugging Face on SageMaker\\nTopic Icon\\nAWS Lambda + API Gateway\\nTopic Icon\\nServerless LLM pipelines\\nTopic Icon\\nEvent-driven prompt processing\\nTopic Icon\\nAWS S3 + DynamoDB\\nTopic Icon\\nStore prompt history, logs, and outputs\\nTopic Icon\\nHosting RAG Application\\nTopic Icon\\nLLM + FAISS + OpenSearch + FastAPI\\n\\nGenAI on Azure\\nTopic Icon\\nAzure OpenAI Service\\nTopic Icon\\nUsing GPT-4, Codex, and Embeddings via Azure\\nTopic Icon\\nRate limiting, usage quotas, regions\\nTopic Icon\\nAzure ML + Hugging Face\\nTopic Icon\\nFine-tune or deploy LLaMA/DistilGPT on managed compute\\nTopic Icon\\nAzure Functions for Inference\\nTopic Icon\\nStateless REST APIs for prompt → response\\nTopic Icon\\nAzure Blob Storage & Cosmos DB\\nTopic Icon\\nFile + text chunk storage and metadata handling\\nTopic Icon\\nAzure AI Search + RAG Setup\\nTopic Icon\\nIndex unstructured data and use with GPT\\n\\nGenAI on Google Cloud (GCP)\\nTopic Icon\\nGemini (Vertex AI Studio)\\nTopic Icon\\nGemini 1.5 Pro Prompting, JSON Structuring\\nTopic Icon\\nAPI key access & project setup\\nTopic Icon\\nVertex AI PaLM Models\\nTopic Icon\\nText & chat APIs\\nTopic Icon\\nEmbeddings + RAG in Vertex pipelines\\nTopic Icon\\nCloud Functions & Cloud Run\\nTopic Icon\\nDeploy APIs for chatbots or assistants\\nTopic Icon\\nBigQuery + Cloud Storage\\nTopic Icon\\nLogging prompt-response cycles\\nTopic Icon\\nMetadata store for prompt experiments\\n\\nHugging Face & Open-Source Cloud Deployments\\nTopic Icon\\nHugging Face Inference Endpoints\\nTopic Icon\\nDeploy custom models (Falcon, Mistral, Bloom)\\nTopic Icon\\nControl security, auth, autoscaling\\nTopic Icon\\nSpaces with Gradio & Streamlit\\nTopic Icon\\nBuild GenAI UI on Hugging Face Spaces\\nTopic Icon\\nShare projects publicly or privately\\nTopic Icon\\nWeights & Biases for Prompt/Model Tracking\\nTopic Icon\\nOpen-Source on GPU VMs (EC2/GCP/Azure)\\nTopic Icon\\nRun models via Docker (text-generation-webui, llama.cpp)\\nTopic Icon\\nModel quantization + LoRA\\n\\nVector DBs & Embedding Integration in Cloud\\nTopic Icon\\nEmbedding Models\\nTopic Icon\\nOpenAI, Cohere, Hugging Face, Gemini Text Embedding APIs\\nTopic Icon\\nCloud Vector Stores\\nTopic Icon\\nPinecone\\nTopic Icon\\nWeaviate on GCP\\nTopic Icon\\nChromaDB on EC2 / Azure\\nTopic Icon\\nQdrant Cloud\\nTopic Icon\\nConnecting LangChain / LlamaIndex\\nTopic Icon\\nRAG Pipelines in Cloud + Vector Store + UI\\n\\nPrompt Engineering & LLMOps in Cloud\\nTopic Icon\\nPrompt Lifecycle in Production\\nTopic Icon\\nPrompt Templates & Reusability (LangChain + PromptLayer)\\nTopic Icon\\nLLM Evaluation: GPT Judge, Trulens\\nTopic Icon\\nCI/CD for GenAI Apps\\nTopic Icon\\nGitHub Actions, DockerHub\\nTopic Icon\\nAuto-deploy Streamlit/FastAPI via Railway/Render/Cloud Run\\n\\nAgents, Tools & Cloud APIs\\nTopic Icon\\nLangChain Agents + Cloud Functions\\nTopic Icon\\nCrewAI Agents Hosted on Render/EC2\\nTopic Icon\\nOpenAI Tools (Function Calling)\\nTopic Icon\\nRetrieval APIs + Calendar APIs + Google Sheets APIs\\nTopic Icon\\nZapier/N8N Integration in Agent Flows\\n\\nGenAI Monitoring & Logging\\nTopic Icon\\nLog Everything: Prompt, Completion, User Input, Token Usage\\nTopic Icon\\nCloud Observability Tools\\nTopic Icon\\nAWS CloudWatch\\nTopic Icon\\nAzure Monitor\\nTopic Icon\\nGCP Logging\\nTopic Icon\\nDashboarding with Grafana / Superset\\nTopic Icon\\nFail-Safe Mechanisms (Fallback Prompts, Retry on Token Errors)\\n\\nSecurity, Compliance & Cost Management\\nTopic Icon\\nSecrets Management (AWS Secrets Manager, Azure Key Vault)\\nTopic Icon\\nSecure Access to APIs (JWT, OAuth, API Keys)\\nTopic Icon\\nModel Cost Estimation (OpenAI Token Cost, API Cost Logs)\\nTopic Icon\\nUsage Quotas & Budget Alerts\\nTopic Icon\\nCompliance Guidelines: SOC2, HIPAA, GDPR in GenAI Apps\\n\\nCapstone Projects (Cloud-Based)\\nTopic Icon\\nProject 1: PDF + Website Knowledge Chatbot\\nTopic Icon\\nGCP + Gemini + FAISS + Streamlit UI\\nTopic Icon\\nProject 2: Image + Text Generator\\nTopic Icon\\nAWS Bedrock (Titan + Claude) + Gradio + S3 Storage\\nTopic Icon\\nProject 3: Serverless Resume Analyzer\\nTopic Icon\\nAzure OpenAI + Functions + CosmosDB + Blob Storage\\nTopic Icon\\nProject 4: LLM Agent + Tool Integration\\nTopic Icon\\nCrewAI + FastAPI + N8N on EC2\\nTopic Icon\\nProject 5: Enterprise GenAI Analytics App\\nTopic Icon\\nPrompt Evaluator + Feedback + Logging Dashboard + Multi-user Auth\\nShow less sections\\nMeet Your Instructors\\nSudhanshu Kumar's profile\\nSudhanshu Kumar\\nProgramming | Data Science | Machine Learning | Deep Learning | NLP | Computer Vision | Generative AI | Big Data | Data Analytics\\n\\nMy journey has been one of dedication, resilience, and a deeply personal mission to make education accessible to everyone. Coming from a humble background in Jamshedpur, Jharkhand, I know firsthand the challenges of pursuing quality education without financial ease. My early experiences motiva...\")]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "document = TextLoader(\"sudhanshuinfo.txt\").load()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e017002",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
    "docs = splitter.split_documents(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15766867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec2d8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Making an Impact\\nHelping Millions of Students Succeed'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students,\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"The Entrepreneur and Teacher: Sudhanshu's Dual Legacy\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"Sudhanshu's journey isn't just one of entrepreneurial success; it's also a story of dedication to teaching. Throughout his career, he has remained a passionate educator, constantly looking for ways to empower others through knowledge. Whether teaching courses in Big Data, Data Science, or\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='in Big Data, Data Science, or programming, Sudhanshu has always sought to make complex subjects accessible to learners at all levels.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='His commitment to affordable education has earned him the respect and admiration of countless students. Many credit Sudhanshu with changing their lives, helping them secure jobs, improve their skills, and break free from the limitations of their backgrounds.\\n\\nThe Journey'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='The Journey\\n\\nEarly Life and the Power of Education\\n\\nRising Through the Ranks of the Tech World\\n\\nThe Birth of iNeuron: Democratizing Education'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='The Foundation of Euron: Expanding the Mission\\nEarly Life and the Power of Education\\nEarly Life and the Power of Education'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"Sudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity,\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='While many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='After completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Despite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Fueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='iNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='was priced to ensure no student would be left behind due to financial constraints.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"The company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience.\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Building on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"For individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='The Euron Motto: Education for All, Without Limits'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"At the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Home >'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Generative AI\\nGenerative AI with Cloud'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Generative AI with Cloud is a practical course that combines generative AI techniques with cloud platforms like AWS, Azure, and GCP. Learn to deploy and scale models, integrate APIs, manage storage, and build intelligent applications using tools like Vertex AI, Bedrock, and OpenAI. Ideal for'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='and OpenAI. Ideal for real-world, cloud-powered AI solutions.'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='🌐\\nEnglish\\nGenerative AI with Cloud\\nThis course is included in plans\\n\\n📚\\nContinue Learning\\nWhat you will get\\ntick-svg\\nCertificate of Completion\\n\\ntick-svg\\nWhatsApp Group Access\\n\\ntick-svg\\nEURI AI Tool Access\\n\\ntick-svg\\nResume AI Tool\\n\\ntick-svg\\nJob Portal Access\\n\\ntick-svg\\nAvni – AI Interview Coach'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='tick-svg\\nNo Prerequisites Required\\n\\ntick-svg\\nQuiz in Every Module\\n\\ntick-svg\\nChallenges in Every Module\\n\\ntick-svg\\nCareer-Ready Portfolio\\n\\ntick-svg\\nResources in all Module\\n\\ntick-svg\\nOne module release every Monday\\n\\nCourse content\\n12 sections • 100 Subtopics\\n\\nCollapse all sections'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Introduction to Generative AI in the Cloud\\nTopic Icon\\nWhat is Generative AI in a Cloud Context?\\nTopic Icon\\nDifferences Between Local vs Cloud-Based Generative AI\\nTopic Icon\\nUse Cases: AI Agents, Chatbots, Text-to-Image, Code Assistants\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nCloud Provider Comparison: AWS vs Azure vs GCP vs Hugging Face vs OpenAI\\nTopic Icon\\nKey Components: Model APIs, Storage, Serverless Compute, GPU Instances, Vector DBs'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='GenAI Building Blocks & Architecture\\nTopic Icon\\nCore Architecture: Frontend ↔ API Layer ↔ Model ↔ Storage\\nTopic Icon\\nDeployment Flow: Prompt → Model API → Output → Logging\\nTopic Icon\\nCloud GenAI Architecture Patterns\\nTopic Icon\\nRAG Pipeline\\nTopic Icon\\nAgent Execution Flow\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nImage + Text Generation\\nTopic Icon\\nDev Tools: GitHub, VS Code, LangChain, Streamlit/Gradio, FastAPI'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='GenAI on AWS\\nTopic Icon\\nAWS Bedrock\\nTopic Icon\\nAccessing Claude, Titan, LLaMA via Bedrock\\nTopic Icon\\nBedrock API setup and playground\\nTopic Icon\\nAmazon SageMaker JumpStart\\nTopic Icon\\nDeploying Pre-trained Foundation Models (T5, Falcon)\\nTopic Icon\\nFine-Tuning & Inference Endpoint\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nHugging Face on SageMaker\\nTopic Icon\\nAWS Lambda + API Gateway\\nTopic Icon\\nServerless LLM pipelines\\nTopic Icon\\nEvent-driven prompt processing\\nTopic Icon\\nAWS S3 + DynamoDB\\nTopic Icon\\nStore prompt history, logs, and outputs\\nTopic Icon\\nHosting RAG Application\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nLLM + FAISS + OpenSearch + FastAPI'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='GenAI on Azure\\nTopic Icon\\nAzure OpenAI Service\\nTopic Icon\\nUsing GPT-4, Codex, and Embeddings via Azure\\nTopic Icon\\nRate limiting, usage quotas, regions\\nTopic Icon\\nAzure ML + Hugging Face\\nTopic Icon\\nFine-tune or deploy LLaMA/DistilGPT on managed compute\\nTopic Icon\\nAzure Functions for Inference'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Azure Functions for Inference\\nTopic Icon\\nStateless REST APIs for prompt → response\\nTopic Icon\\nAzure Blob Storage & Cosmos DB\\nTopic Icon\\nFile + text chunk storage and metadata handling\\nTopic Icon\\nAzure AI Search + RAG Setup\\nTopic Icon\\nIndex unstructured data and use with GPT'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='GenAI on Google Cloud (GCP)\\nTopic Icon\\nGemini (Vertex AI Studio)\\nTopic Icon\\nGemini 1.5 Pro Prompting, JSON Structuring\\nTopic Icon\\nAPI key access & project setup\\nTopic Icon\\nVertex AI PaLM Models\\nTopic Icon\\nText & chat APIs\\nTopic Icon\\nEmbeddings + RAG in Vertex pipelines\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nCloud Functions & Cloud Run\\nTopic Icon\\nDeploy APIs for chatbots or assistants\\nTopic Icon\\nBigQuery + Cloud Storage\\nTopic Icon\\nLogging prompt-response cycles\\nTopic Icon\\nMetadata store for prompt experiments'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Hugging Face & Open-Source Cloud Deployments\\nTopic Icon\\nHugging Face Inference Endpoints\\nTopic Icon\\nDeploy custom models (Falcon, Mistral, Bloom)\\nTopic Icon\\nControl security, auth, autoscaling\\nTopic Icon\\nSpaces with Gradio & Streamlit\\nTopic Icon\\nBuild GenAI UI on Hugging Face Spaces\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nShare projects publicly or privately\\nTopic Icon\\nWeights & Biases for Prompt/Model Tracking\\nTopic Icon\\nOpen-Source on GPU VMs (EC2/GCP/Azure)\\nTopic Icon\\nRun models via Docker (text-generation-webui, llama.cpp)\\nTopic Icon\\nModel quantization + LoRA'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Vector DBs & Embedding Integration in Cloud\\nTopic Icon\\nEmbedding Models\\nTopic Icon\\nOpenAI, Cohere, Hugging Face, Gemini Text Embedding APIs\\nTopic Icon\\nCloud Vector Stores\\nTopic Icon\\nPinecone\\nTopic Icon\\nWeaviate on GCP\\nTopic Icon\\nChromaDB on EC2 / Azure\\nTopic Icon\\nQdrant Cloud\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Qdrant Cloud\\nTopic Icon\\nConnecting LangChain / LlamaIndex\\nTopic Icon\\nRAG Pipelines in Cloud + Vector Store + UI'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Prompt Engineering & LLMOps in Cloud\\nTopic Icon\\nPrompt Lifecycle in Production\\nTopic Icon\\nPrompt Templates & Reusability (LangChain + PromptLayer)\\nTopic Icon\\nLLM Evaluation: GPT Judge, Trulens\\nTopic Icon\\nCI/CD for GenAI Apps\\nTopic Icon\\nGitHub Actions, DockerHub\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nAuto-deploy Streamlit/FastAPI via Railway/Render/Cloud Run'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Agents, Tools & Cloud APIs\\nTopic Icon\\nLangChain Agents + Cloud Functions\\nTopic Icon\\nCrewAI Agents Hosted on Render/EC2\\nTopic Icon\\nOpenAI Tools (Function Calling)\\nTopic Icon\\nRetrieval APIs + Calendar APIs + Google Sheets APIs\\nTopic Icon\\nZapier/N8N Integration in Agent Flows'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='GenAI Monitoring & Logging\\nTopic Icon\\nLog Everything: Prompt, Completion, User Input, Token Usage\\nTopic Icon\\nCloud Observability Tools\\nTopic Icon\\nAWS CloudWatch\\nTopic Icon\\nAzure Monitor\\nTopic Icon\\nGCP Logging\\nTopic Icon\\nDashboarding with Grafana / Superset\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nFail-Safe Mechanisms (Fallback Prompts, Retry on Token Errors)'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Security, Compliance & Cost Management\\nTopic Icon\\nSecrets Management (AWS Secrets Manager, Azure Key Vault)\\nTopic Icon\\nSecure Access to APIs (JWT, OAuth, API Keys)\\nTopic Icon\\nModel Cost Estimation (OpenAI Token Cost, API Cost Logs)\\nTopic Icon\\nUsage Quotas & Budget Alerts\\nTopic Icon'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nCompliance Guidelines: SOC2, HIPAA, GDPR in GenAI Apps'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Capstone Projects (Cloud-Based)\\nTopic Icon\\nProject 1: PDF + Website Knowledge Chatbot\\nTopic Icon\\nGCP + Gemini + FAISS + Streamlit UI\\nTopic Icon\\nProject 2: Image + Text Generator\\nTopic Icon\\nAWS Bedrock (Titan + Claude) + Gradio + S3 Storage\\nTopic Icon\\nProject 3: Serverless Resume Analyzer'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='Topic Icon\\nAzure OpenAI + Functions + CosmosDB + Blob Storage\\nTopic Icon\\nProject 4: LLM Agent + Tool Integration\\nTopic Icon\\nCrewAI + FastAPI + N8N on EC2\\nTopic Icon\\nProject 5: Enterprise GenAI Analytics App\\nTopic Icon\\nPrompt Evaluator + Feedback + Logging Dashboard + Multi-user Auth'),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content=\"Show less sections\\nMeet Your Instructors\\nSudhanshu Kumar's profile\\nSudhanshu Kumar\\nProgramming | Data Science | Machine Learning | Deep Learning | NLP | Computer Vision | Generative AI | Big Data | Data Analytics\"),\n",
       " Document(metadata={'source': 'sudhanshuinfo.txt'}, page_content='My journey has been one of dedication, resilience, and a deeply personal mission to make education accessible to everyone. Coming from a humble background in Jamshedpur, Jharkhand, I know firsthand the challenges of pursuing quality education without financial ease. My early experiences motiva...')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be24ac07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Making an Impact\\nHelping Millions of Students Succeed',\n",
       " \"Sudhanshu's commitment to affordable education wasn't just a business strategy—it was his life's mission. Over the years, iNeuron has helped over 1.5 million students from 34+ countries, providing them with the skills they need to succeed in today's competitive job market. Many of these students,\",\n",
       " 'Many of these students, like Sudhanshu himself, came from disadvantaged backgrounds. They saw iNeuron as a lifeline—an opportunity to rise above their circumstances.',\n",
       " 'In 2022, iNeuron was acquired by PhysicsWallah in a deal worth ₹250 crore. While this acquisition was a significant milestone, Sudhanshu remained focused on his mission. Even after the acquisition, iNeuron continued to offer some of the most affordable and accessible tech courses in the world.',\n",
       " \"The Entrepreneur and Teacher: Sudhanshu's Dual Legacy\",\n",
       " \"Sudhanshu's journey isn't just one of entrepreneurial success; it's also a story of dedication to teaching. Throughout his career, he has remained a passionate educator, constantly looking for ways to empower others through knowledge. Whether teaching courses in Big Data, Data Science, or\",\n",
       " 'in Big Data, Data Science, or programming, Sudhanshu has always sought to make complex subjects accessible to learners at all levels.',\n",
       " 'His commitment to affordable education has earned him the respect and admiration of countless students. Many credit Sudhanshu with changing their lives, helping them secure jobs, improve their skills, and break free from the limitations of their backgrounds.\\n\\nThe Journey',\n",
       " 'The Journey\\n\\nEarly Life and the Power of Education\\n\\nRising Through the Ranks of the Tech World\\n\\nThe Birth of iNeuron: Democratizing Education',\n",
       " 'The Foundation of Euron: Expanding the Mission\\nEarly Life and the Power of Education\\nEarly Life and the Power of Education',\n",
       " \"Sudhanshu Kumar's life is a story of triumph over adversity, driven by the belief in the transformative power of education. Born in Jamshedpur, Jharkhand, India, to a family of very modest means, Sudhanshu's early years were marked by financial hardship. His surroundings offered little opportunity,\",\n",
       " 'offered little opportunity, and resources were limited, yet he understood from a young age that education could be his ticket out of poverty.',\n",
       " 'While many would have been daunted by the lack of support and opportunity, Sudhanshu was relentless in his pursuit of knowledge. He knew that education had the power to change lives, and he was determined to leverage it to create a better future for himself and his family. Despite the numerous',\n",
       " 'family. Despite the numerous challenges along the way, Sudhanshu excelled academically, eventually earning a degree in Computer Science and Engineering (CSE).',\n",
       " 'After completing his education, Sudhanshu began his professional journey in the tech industry, working with prestigious companies like Wipro, Deloitte, Verizon Labs, and Ernst & Young. During this time, he gained expertise in various technologies and frameworks, including SAP WebDynpro, Fiori UI5',\n",
       " 'SAP WebDynpro, Fiori UI5 HANA, Java, Big Data, Data Analytics, and more. He became a well-rounded technologist, well-respected in his field.',\n",
       " 'Despite his growing success, Sudhanshu never forgot his roots. He knew that there were many others who, like him, came from humble backgrounds and were looking for an opportunity to change their lives through education. It was during this time that Sudhanshu realized a harsh truth: quality',\n",
       " 'a harsh truth: quality education was often inaccessible to those who needed it the most. The high cost of education barred millions of people from pursuing their dreams, especially in tech fields that required specialized skills.',\n",
       " 'Fueled by his passion for making education accessible, Sudhanshu decided to take action. In 2019, he founded iNeuron Intelligence Private Limited, an edtech platform that would make tech upskilling affordable and accessible for everyone. His mission was clear: to provide high-quality courses at a',\n",
       " 'high-quality courses at a price so low that even those from the most disadvantaged backgrounds could afford to learn.',\n",
       " 'iNeuron was designed to be more than just an online learning platform. It offered a comprehensive bundle of resources, including courses, books, hands-on projects, and live classes, making sure that learners could gain real-world, applicable skills. Most importantly, iNeuron was priced to ensure no',\n",
       " 'was priced to ensure no student would be left behind due to financial constraints.',\n",
       " \"The company quickly gained traction, thanks to Sudhanshu's focus on affordability and quality. In 2021, iNeuron raised $3 million in funding from S. Chand, a leading education publisher. This allowed iNeuron to expand its offerings and reach a larger audience.\",\n",
       " 'Building on the success of iNeuron, Sudhanshu is now leading Euron, a unified platform for tech upskilling. Euron is designed for enterprises, schools, colleges, government organizations, and individuals looking to improve their tech skills. The platform provides a comprehensive bundle of',\n",
       " \"a comprehensive bundle of resources, including courses, books, live classes, and projects. Euron's unique offering is its ability to provide licenses at scale—organizations can subscribe to provide their teams with unlimited access to learning materials for just 1600 INR per year per license.\",\n",
       " \"For individuals, Euron Plus offers a similar plan, priced at 2900 INR per year, giving learners access to all of Euron's content, along with 24/7 support through Euron Assist. The idea is simple: anyone, anywhere, should have the opportunity to upskill without financial barriers.\",\n",
       " 'The Euron Motto: Education for All, Without Limits',\n",
       " \"At the heart of Euron's philosophy is a single, powerful idea: Education for All, Without Limits. Sudhanshu believes that every person deserves the chance to learn, grow, and succeed, regardless of their financial situation or background. This belief is what drives Euron's mission to make tech\",\n",
       " \"Euron's mission to make tech education not just affordable but also accessible to anyone, anywhere in the world.\",\n",
       " 'Home >',\n",
       " 'Generative AI\\nGenerative AI with Cloud',\n",
       " 'Generative AI with Cloud is a practical course that combines generative AI techniques with cloud platforms like AWS, Azure, and GCP. Learn to deploy and scale models, integrate APIs, manage storage, and build intelligent applications using tools like Vertex AI, Bedrock, and OpenAI. Ideal for',\n",
       " 'and OpenAI. Ideal for real-world, cloud-powered AI solutions.',\n",
       " '🌐\\nEnglish\\nGenerative AI with Cloud\\nThis course is included in plans\\n\\n📚\\nContinue Learning\\nWhat you will get\\ntick-svg\\nCertificate of Completion\\n\\ntick-svg\\nWhatsApp Group Access\\n\\ntick-svg\\nEURI AI Tool Access\\n\\ntick-svg\\nResume AI Tool\\n\\ntick-svg\\nJob Portal Access\\n\\ntick-svg\\nAvni – AI Interview Coach',\n",
       " 'tick-svg\\nNo Prerequisites Required\\n\\ntick-svg\\nQuiz in Every Module\\n\\ntick-svg\\nChallenges in Every Module\\n\\ntick-svg\\nCareer-Ready Portfolio\\n\\ntick-svg\\nResources in all Module\\n\\ntick-svg\\nOne module release every Monday\\n\\nCourse content\\n12 sections • 100 Subtopics\\n\\nCollapse all sections',\n",
       " 'Introduction to Generative AI in the Cloud\\nTopic Icon\\nWhat is Generative AI in a Cloud Context?\\nTopic Icon\\nDifferences Between Local vs Cloud-Based Generative AI\\nTopic Icon\\nUse Cases: AI Agents, Chatbots, Text-to-Image, Code Assistants\\nTopic Icon',\n",
       " 'Topic Icon\\nCloud Provider Comparison: AWS vs Azure vs GCP vs Hugging Face vs OpenAI\\nTopic Icon\\nKey Components: Model APIs, Storage, Serverless Compute, GPU Instances, Vector DBs',\n",
       " 'GenAI Building Blocks & Architecture\\nTopic Icon\\nCore Architecture: Frontend ↔ API Layer ↔ Model ↔ Storage\\nTopic Icon\\nDeployment Flow: Prompt → Model API → Output → Logging\\nTopic Icon\\nCloud GenAI Architecture Patterns\\nTopic Icon\\nRAG Pipeline\\nTopic Icon\\nAgent Execution Flow\\nTopic Icon',\n",
       " 'Topic Icon\\nImage + Text Generation\\nTopic Icon\\nDev Tools: GitHub, VS Code, LangChain, Streamlit/Gradio, FastAPI',\n",
       " 'GenAI on AWS\\nTopic Icon\\nAWS Bedrock\\nTopic Icon\\nAccessing Claude, Titan, LLaMA via Bedrock\\nTopic Icon\\nBedrock API setup and playground\\nTopic Icon\\nAmazon SageMaker JumpStart\\nTopic Icon\\nDeploying Pre-trained Foundation Models (T5, Falcon)\\nTopic Icon\\nFine-Tuning & Inference Endpoint\\nTopic Icon',\n",
       " 'Topic Icon\\nHugging Face on SageMaker\\nTopic Icon\\nAWS Lambda + API Gateway\\nTopic Icon\\nServerless LLM pipelines\\nTopic Icon\\nEvent-driven prompt processing\\nTopic Icon\\nAWS S3 + DynamoDB\\nTopic Icon\\nStore prompt history, logs, and outputs\\nTopic Icon\\nHosting RAG Application\\nTopic Icon',\n",
       " 'Topic Icon\\nLLM + FAISS + OpenSearch + FastAPI',\n",
       " 'GenAI on Azure\\nTopic Icon\\nAzure OpenAI Service\\nTopic Icon\\nUsing GPT-4, Codex, and Embeddings via Azure\\nTopic Icon\\nRate limiting, usage quotas, regions\\nTopic Icon\\nAzure ML + Hugging Face\\nTopic Icon\\nFine-tune or deploy LLaMA/DistilGPT on managed compute\\nTopic Icon\\nAzure Functions for Inference',\n",
       " 'Azure Functions for Inference\\nTopic Icon\\nStateless REST APIs for prompt → response\\nTopic Icon\\nAzure Blob Storage & Cosmos DB\\nTopic Icon\\nFile + text chunk storage and metadata handling\\nTopic Icon\\nAzure AI Search + RAG Setup\\nTopic Icon\\nIndex unstructured data and use with GPT',\n",
       " 'GenAI on Google Cloud (GCP)\\nTopic Icon\\nGemini (Vertex AI Studio)\\nTopic Icon\\nGemini 1.5 Pro Prompting, JSON Structuring\\nTopic Icon\\nAPI key access & project setup\\nTopic Icon\\nVertex AI PaLM Models\\nTopic Icon\\nText & chat APIs\\nTopic Icon\\nEmbeddings + RAG in Vertex pipelines\\nTopic Icon',\n",
       " 'Topic Icon\\nCloud Functions & Cloud Run\\nTopic Icon\\nDeploy APIs for chatbots or assistants\\nTopic Icon\\nBigQuery + Cloud Storage\\nTopic Icon\\nLogging prompt-response cycles\\nTopic Icon\\nMetadata store for prompt experiments',\n",
       " 'Hugging Face & Open-Source Cloud Deployments\\nTopic Icon\\nHugging Face Inference Endpoints\\nTopic Icon\\nDeploy custom models (Falcon, Mistral, Bloom)\\nTopic Icon\\nControl security, auth, autoscaling\\nTopic Icon\\nSpaces with Gradio & Streamlit\\nTopic Icon\\nBuild GenAI UI on Hugging Face Spaces\\nTopic Icon',\n",
       " 'Topic Icon\\nShare projects publicly or privately\\nTopic Icon\\nWeights & Biases for Prompt/Model Tracking\\nTopic Icon\\nOpen-Source on GPU VMs (EC2/GCP/Azure)\\nTopic Icon\\nRun models via Docker (text-generation-webui, llama.cpp)\\nTopic Icon\\nModel quantization + LoRA',\n",
       " 'Vector DBs & Embedding Integration in Cloud\\nTopic Icon\\nEmbedding Models\\nTopic Icon\\nOpenAI, Cohere, Hugging Face, Gemini Text Embedding APIs\\nTopic Icon\\nCloud Vector Stores\\nTopic Icon\\nPinecone\\nTopic Icon\\nWeaviate on GCP\\nTopic Icon\\nChromaDB on EC2 / Azure\\nTopic Icon\\nQdrant Cloud\\nTopic Icon',\n",
       " 'Qdrant Cloud\\nTopic Icon\\nConnecting LangChain / LlamaIndex\\nTopic Icon\\nRAG Pipelines in Cloud + Vector Store + UI',\n",
       " 'Prompt Engineering & LLMOps in Cloud\\nTopic Icon\\nPrompt Lifecycle in Production\\nTopic Icon\\nPrompt Templates & Reusability (LangChain + PromptLayer)\\nTopic Icon\\nLLM Evaluation: GPT Judge, Trulens\\nTopic Icon\\nCI/CD for GenAI Apps\\nTopic Icon\\nGitHub Actions, DockerHub\\nTopic Icon',\n",
       " 'Topic Icon\\nAuto-deploy Streamlit/FastAPI via Railway/Render/Cloud Run',\n",
       " 'Agents, Tools & Cloud APIs\\nTopic Icon\\nLangChain Agents + Cloud Functions\\nTopic Icon\\nCrewAI Agents Hosted on Render/EC2\\nTopic Icon\\nOpenAI Tools (Function Calling)\\nTopic Icon\\nRetrieval APIs + Calendar APIs + Google Sheets APIs\\nTopic Icon\\nZapier/N8N Integration in Agent Flows',\n",
       " 'GenAI Monitoring & Logging\\nTopic Icon\\nLog Everything: Prompt, Completion, User Input, Token Usage\\nTopic Icon\\nCloud Observability Tools\\nTopic Icon\\nAWS CloudWatch\\nTopic Icon\\nAzure Monitor\\nTopic Icon\\nGCP Logging\\nTopic Icon\\nDashboarding with Grafana / Superset\\nTopic Icon',\n",
       " 'Topic Icon\\nFail-Safe Mechanisms (Fallback Prompts, Retry on Token Errors)',\n",
       " 'Security, Compliance & Cost Management\\nTopic Icon\\nSecrets Management (AWS Secrets Manager, Azure Key Vault)\\nTopic Icon\\nSecure Access to APIs (JWT, OAuth, API Keys)\\nTopic Icon\\nModel Cost Estimation (OpenAI Token Cost, API Cost Logs)\\nTopic Icon\\nUsage Quotas & Budget Alerts\\nTopic Icon',\n",
       " 'Topic Icon\\nCompliance Guidelines: SOC2, HIPAA, GDPR in GenAI Apps',\n",
       " 'Capstone Projects (Cloud-Based)\\nTopic Icon\\nProject 1: PDF + Website Knowledge Chatbot\\nTopic Icon\\nGCP + Gemini + FAISS + Streamlit UI\\nTopic Icon\\nProject 2: Image + Text Generator\\nTopic Icon\\nAWS Bedrock (Titan + Claude) + Gradio + S3 Storage\\nTopic Icon\\nProject 3: Serverless Resume Analyzer',\n",
       " 'Topic Icon\\nAzure OpenAI + Functions + CosmosDB + Blob Storage\\nTopic Icon\\nProject 4: LLM Agent + Tool Integration\\nTopic Icon\\nCrewAI + FastAPI + N8N on EC2\\nTopic Icon\\nProject 5: Enterprise GenAI Analytics App\\nTopic Icon\\nPrompt Evaluator + Feedback + Logging Dashboard + Multi-user Auth',\n",
       " \"Show less sections\\nMeet Your Instructors\\nSudhanshu Kumar's profile\\nSudhanshu Kumar\\nProgramming | Data Science | Machine Learning | Deep Learning | NLP | Computer Vision | Generative AI | Big Data | Data Analytics\",\n",
       " 'My journey has been one of dedication, resilience, and a deeply personal mission to make education accessible to everyone. Coming from a humble background in Jamshedpur, Jharkhand, I know firsthand the challenges of pursuing quality education without financial ease. My early experiences motiva...']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [doc.page_content for doc in docs]\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "843e3270",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embeddings = \u001b[43m[\u001b[49m\u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m embeddings = [\u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m texts]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mgenerate_embeddings\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     16\u001b[39m data = response.json()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Convert to numpy array for vector operations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m embedding = np.array(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n",
      "\u001b[31mKeyError\u001b[39m: 'data'"
     ]
    }
   ],
   "source": [
    "embeddings = [generate_embeddings(i) for i in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "139fbefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00645238, -0.02682346, -0.02852873, ..., -0.00969585,\n",
       "        0.01474829, -0.00714371], shape=(1536,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_embeddings(\"my name is sudhanshu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3767520c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02033959,  0.0112574 ,  0.01501457, ...,  0.0141459 ,\n",
       "       -0.01669541, -0.00123944], shape=(1536,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_embeddings(\"This is a test input.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf4030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/61: Making an Impact\n",
      "Helping Milli... -> [ 0.03395454 -0.0469909   0.03878181  0.07887272  0.02695909]\n",
      "Processed 2/61: Sudhanshu's commitment to affo... -> [-0.01364236  0.00639423  0.05721121  0.02440282  0.04653747]\n",
      "Processed 3/61: Many of these students, like S... -> [-0.02204193 -0.00722562  0.00345266  0.03793968  0.04818918]\n",
      "Processed 4/61: In 2022, iNeuron was acquired ... -> [-0.04330519 -0.05195538  0.02764536  0.0217475   0.03644469]\n",
      "Processed 5/61: The Entrepreneur and Teacher: ... -> [0.01671011 0.01011956 0.04287479 0.01667061 0.00875009]\n",
      "Processed 6/61: Sudhanshu's journey isn't just... -> [-0.00970297 -0.00214104  0.0598214   0.02851626  0.0276796 ]\n",
      "Processed 7/61: in Big Data, Data Science, or ... -> [-0.00566224 -0.01421534  0.03512025 -0.01587579  0.05972831]\n",
      "Processed 8/61: His commitment to affordable e... -> [ 0.01117547 -0.04308555  0.04391897  0.05712749  0.01579719]\n"
     ]
    }
   ],
   "source": [
    "  = []\n",
    "valid_texts = []\n",
    "for i ,text in enumerate(texts[0:8]):\n",
    "    clean_text = text.strip()\n",
    "    if not clean_text:\n",
    "        print(f\"Skipping empty text at index {i}\")\n",
    "        continue\n",
    "    embedding = generate_embeddings(text)\n",
    "    embeddings.append(embedding)\n",
    "    valid_texts.append(text)embeddings\n",
    "    print(f\"Processed {i+1}/{len(texts)}: {text[:30]}... -> {embedding[:5]}\")  # Print first 30 characters of text and first 5 elements of embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "749fc2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.03395454, -0.0469909 ,  0.03878181, ..., -0.02398636,\n",
       "        -0.01851818,  0.01633636], shape=(1536,)),\n",
       " array([-0.01364236,  0.00639423,  0.05721121, ..., -0.00413274,\n",
       "        -0.00975312, -0.00021493], shape=(1536,)),\n",
       " array([-0.02204193, -0.00722562,  0.00345266, ..., -0.00756314,\n",
       "        -0.02643654, -0.00205438], shape=(1536,)),\n",
       " array([-0.04330519, -0.05195538,  0.02764536, ..., -0.03267549,\n",
       "         0.01820879,  0.03354321], shape=(1536,)),\n",
       " array([ 0.01671011,  0.01011956,  0.04287479, ..., -0.04371754,\n",
       "         0.01135734, -0.00684733], shape=(1536,)),\n",
       " array([-0.00970297, -0.00214104,  0.0598214 , ..., -0.01701214,\n",
       "        -0.01090567,  0.00101315], shape=(1536,)),\n",
       " array([-0.00566224, -0.01421534,  0.03512025, ..., -0.00708975,\n",
       "         0.00744215,  0.00205764], shape=(1536,)),\n",
       " array([ 0.01117547, -0.04308555,  0.04391897, ...,  0.00480482,\n",
       "        -0.02457341,  0.01011475], shape=(1536,))]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02372453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Processing 1/61...\n",
      "🔄 Processing 2/61...\n",
      "🔄 Processing 3/61...\n",
      "🔄 Processing 4/61...\n",
      "🔄 Processing 5/61...\n",
      "🔄 Processing 6/61...\n",
      "🔄 Processing 7/61...\n",
      "🔄 Processing 8/61...\n",
      "🔄 Processing 9/61...\n",
      "🔄 Processing 10/61...\n",
      "🔄 Processing 11/61...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🔄 Processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     embedding = \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m.astype(\u001b[33m'\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m     embeddings.append(embedding)\n\u001b[32m     11\u001b[39m     time.sleep(\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# ⏳ Add delay to respect API rate limits\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mgenerate_embeddings\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m     16\u001b[39m data = response.json()\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Convert to numpy array for vector operations\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m embedding = np.array(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\n",
      "\u001b[31mKeyError\u001b[39m: 'data'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    try:\n",
    "        print(f\"🔄 Processing {i+1}/{len(texts)}...\")\n",
    "        embedding = generate_embeddings(text).astype('float32')\n",
    "        embeddings.append(embedding)\n",
    "        time.sleep(1)  # ⏳ Add delay to respect API rate limits\n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Error on text {i+1}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dbf59fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.03395454, -0.0469909 ,  0.03878181, ..., -0.02398636,\n",
       "        -0.01851818,  0.01633636], shape=(1536,), dtype=float32),\n",
       " array([-0.01364236,  0.00639423,  0.05721121, ..., -0.00413274,\n",
       "        -0.00975312, -0.00021493], shape=(1536,), dtype=float32),\n",
       " array([-0.02204193, -0.00722562,  0.00345266, ..., -0.00756314,\n",
       "        -0.02643654, -0.00205438], shape=(1536,), dtype=float32),\n",
       " array([-0.04330518, -0.05195538,  0.02764536, ..., -0.03267549,\n",
       "         0.01820879,  0.03354321], shape=(1536,), dtype=float32),\n",
       " array([ 0.01671011,  0.01011956,  0.04287479, ..., -0.04371754,\n",
       "         0.01135734, -0.00684733], shape=(1536,), dtype=float32),\n",
       " array([-0.00970297, -0.00214104,  0.0598214 , ..., -0.01701215,\n",
       "        -0.01090567,  0.00101315], shape=(1536,), dtype=float32),\n",
       " array([-0.00568317, -0.01421538,  0.03512035, ..., -0.00705393,\n",
       "         0.00747801,  0.00206959], shape=(1536,), dtype=float32),\n",
       " array([ 0.01117547, -0.04308555,  0.04391897, ...,  0.00480482,\n",
       "        -0.02457341,  0.01011475], shape=(1536,), dtype=float32),\n",
       " array([ 0.01402383, -0.02240153,  0.00623751, ..., -0.00710696,\n",
       "        -0.00134553, -0.01920533], shape=(1536,), dtype=float32),\n",
       " array([ 0.01669836,  0.00235498,  0.04003811, ..., -0.01459751,\n",
       "         0.00198903, -0.03255638], shape=(1536,), dtype=float32)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d90be93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c86c3cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings[0].shape[0]\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "faiss_index.add(np.array(embeddings).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb0f6c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-BVba4WXy4g3mcUWIcXBM4HX0oqKHh', 'object': 'chat.completion', 'created': 1746872329, 'model': 'gpt-4.1-nano', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': \"Hello! Could you please provide more context or specify which Sudhanshu you're referring to? There may be multiple individuals with that name, or it could refer to a person, place, or something else. Providing additional details will help me give you accurate information.\"}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 25, 'completion_tokens': 54, 'total_tokens': 79}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! Could you please provide more context or specify which Sudhanshu you're referring to? There may be multiple individuals with that name, or it could refer to a person, place, or something else. Providing additional details will help me give you accurate information.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"tell me about sudhanshu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9efd60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95265674",
   "metadata": {},
   "outputs": [],
   "source": [
    "RetrievalQA.from_chain_type(llm,retrival)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "423f243f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [Document(page_content=text) for text in texts[:len(embeddings)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc56a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdd33c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4a918a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['62c24928-d3fb-4612-bd1c-93e80e0c4f32',\n",
       " '2f48f22c-2c37-4a17-a737-d5aa68c736db',\n",
       " 'a728f9ce-f880-463a-8fc6-78caf0181cd6',\n",
       " 'db798df8-5897-4558-aa8e-1ca03ec05fe8',\n",
       " 'cba424c8-8577-44fb-8b84-ce2cff35ec84',\n",
       " '869cd529-00ee-4fed-938b-0193a6a78bfc',\n",
       " '404d94b2-e935-47f7-a7cf-bff7c52f5776',\n",
       " '5a7882c0-ea39-404c-a458-e7c338dbbf35',\n",
       " '6947b238-6871-438b-9e35-61186bc1f421',\n",
       " '24c80ee9-52ad-474d-98d7-5fead56e58ae']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "document = [Document(page_content=text) for text in texts[:len(embeddings)]]\n",
    "\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "vector_store = FAISS(\n",
    "    embedding_function=generate_embeddings,\n",
    "    index=faiss_index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")\n",
    "vector_store.add_documents(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fea3ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dac22b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a17d8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb8c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e613b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Through whispers of the ancient breeze,  \n",
      "A traveler moves with silent ease,  \n",
      "Beyond the bounds of present days,  \n",
      "To chase the lost, forgotten rays.\n",
      "\n",
      "With every tick, the clock unwinds,  \n",
      "A bridge through eras, space, and minds,  \n",
      "From dawn's first light to twilight's fade,  \n",
      "In history’s shadows, softly played.\n",
      "\n",
      "The future beckons with a gleam,  \n",
      "A distant, shimmering dream,  \n",
      "While echoes of the past remain,  \n",
      "A haunting, sweet refrain.\n",
      "\n",
      "Time’s gentle river flows and bends,  \n",
      "A story woven without end,  \n",
      "A dance of moments, swift and slow,  \n",
      "Where all our hopes and fears do flow.\n",
      "\n",
      "So, stand on the edge of what has been,  \n",
      "And reach into what might have been,  \n",
      "For time’s great secret, ever spun,  \n",
      "Is only just begun.\n"
     ]
    }
   ],
   "source": [
    "from euriai import EuriaiLangChainLLM\n",
    "\n",
    "llm = EuriaiLangChainLLM(\n",
    "    api_key=EURI_API_KEY,\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "print(llm.invoke(\"Write a poem about time travel.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55ed9499",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever = retriver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f64f535d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scl\\AppData\\Local\\Temp\\ipykernel_45756\\2566710363.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  rag_chain(\"who is sudhanshu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'who is sudhanshu',\n",
       " 'result': 'Sudhanshu is an individual known for his dedication to affordable education and his efforts to empower students through teaching. He has made significant contributions in fields such as Big Data and Data Science, and many students credit him with positively impacting their lives by helping them secure jobs and improve their skills.'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain(\"who is sudhanshu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6d91ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-BVc3adW2OclwQKKpNjdD5LtiKNKHU', 'object': 'chat.completion', 'created': 1746874159, 'model': 'gpt-4.1-nano', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '\"Sudhanshu\" is a common Indian given name, and without additional context, it\\'s difficult to identify a specific individual. It could refer to various people such as professionals, students, or public figures. If you can provide more details or specify the context in which you\\'re asking about Sudhanshu, I’d be happy to help you with more targeted information.'}, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 24, 'completion_tokens': 75, 'total_tokens': 99}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Sudhanshu\" is a common Indian given name, and without additional context, it\\'s difficult to identify a specific individual. It could refer to various people such as professionals, students, or public figures. If you can provide more details or specify the context in which you\\'re asking about Sudhanshu, I’d be happy to help you with more targeted information.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"who is sudhanshu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8cf6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "64c86658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'give me the comapny whre sudhanshu is working',\n",
       " 'result': \"I don't know the name of the company where Sudhanshu is working based on the provided information.\"}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain(\"give me the comapny whre sudhanshu is working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d432e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentdemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
